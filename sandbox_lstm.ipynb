{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c000635b",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24a2572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pipeline.preprocessing import PreProcessing, DataProcessing\n",
    "from pipeline.feature_engineering import FeatureEngineering\n",
    "from pipeline.create_window_tensor import CreateWindowTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race = pd.read_pickle(\"data/race_files/2024-02-23_11_6.pkl\")\n",
    "df_race.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ea918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb33d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.simple_lstm import SimpleLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e3600",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=1e-4, mode='min', verbose=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many validations to wait before stopping if no improvement.\n",
    "            min_delta (float): Minimum change to qualify as improvement.\n",
    "            mode (str): 'min' for minimizing loss, 'max' for maximizing score (e.g., accuracy).\n",
    "            verbose (bool): Whether to print when stopping.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "            return False\n",
    "\n",
    "        improvement = (current_score < self.best_score - self.min_delta) if self.mode == 'min' else (current_score > self.best_score + self.min_delta)\n",
    "\n",
    "        if improvement:\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        return self.early_stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_races_to_tensor(pkl_files,\n",
    "                            training_features,\n",
    "                            target,\n",
    "                            limit_contestants,\n",
    "                            window_timesteps,\n",
    "                            randomize):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for pkl_file in pkl_files:\n",
    "        df_race = pd.read_pickle(pkl_file)\n",
    "\n",
    "        setup = PreProcessing(df=df_race, target=target)\n",
    "\n",
    "        if not setup.valid:\n",
    "            print(f'#### BROKEN DF: {pkl_file}')\n",
    "            print(f'#### STATUS: n_horses: {setup.n_horses}, winner_index: {setup.winner_index}')\n",
    "            print(f'#### SKIPPING')\n",
    "            continue\n",
    "\n",
    "        data_prep = DataProcessing(df=setup.df,\n",
    "                                   winner_index=setup.winner_index,\n",
    "                                   training_features=training_features)\n",
    "\n",
    "        df_data_scaled, _ = data_prep.process_data()\n",
    "\n",
    "        feature_prep = FeatureEngineering(df=df_data_scaled,\n",
    "                                         training_features=training_features,\n",
    "                                         target=target,\n",
    "                                         limit_contestants=limit_contestants,\n",
    "                                         target_int_mapping=setup.target_int_mapping,\n",
    "                                         target_mapping=setup.target_mapping,\n",
    "                                         n_horses=setup.n_horses,\n",
    "                                         winner_index=setup.winner_index)\n",
    "\n",
    "        df_feature, all_good = feature_prep.prepare_features()\n",
    "        if not all_good:\n",
    "            print(f'#### BROKEN DF: {pkl_file}')\n",
    "            print(f'#### STATUS: Not enough horses')\n",
    "            print(f'#### SKIPPING')\n",
    "            continue\n",
    "\n",
    "        if len(df_feature) < window_timesteps:\n",
    "            print(f'#### BROKEN DF: {pkl_file}')\n",
    "            print(f'#### STATUS: Not enough data points')\n",
    "            print(f'#### SKIPPING')\n",
    "            continue\n",
    "\n",
    "        windower = CreateWindowTensor(df=df_feature,\n",
    "                                      target=target,\n",
    "                                      n_horses=limit_contestants,\n",
    "                                      window_timesteps=window_timesteps)\n",
    "\n",
    "        X, y, _ = windower.create_sliding_windows2()\n",
    "\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "\n",
    "    X = np.concatenate(X_list)\n",
    "    y = np.concatenate(y_list)\n",
    "\n",
    "    if randomize:\n",
    "        np.random.seed(42)\n",
    "        indices = np.arange(X.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        X = X[indices]\n",
    "        y = y[indices]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def get_batch(train_files, training_features, target, contestants, window_timesteps, randomize_training_data, val_files=[]):\n",
    "    X_train, y_train = combine_races_to_tensor(\n",
    "        train_files,\n",
    "        training_features,\n",
    "        target,\n",
    "        contestants,\n",
    "        window_timesteps,\n",
    "        randomize_training_data\n",
    "    )\n",
    "    if val_files:\n",
    "        X_val, y_val = combine_races_to_tensor(\n",
    "            val_files,\n",
    "            training_features,\n",
    "            target,\n",
    "            contestants,\n",
    "            window_timesteps,\n",
    "            randomize_training_data\n",
    "        )\n",
    "    else:\n",
    "        X_val, y_val = [], []\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n",
    "def fit_model(model, optimizer, loss_fn, X_train, y_train, X_val, y_val, epochs=5, batch_size=64, device='cuda'):\n",
    "    model.train()\n",
    "    # dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    dataset = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_train, dtype=torch.float32),\n",
    "        torch.tensor(np.argmax(y_train, axis=1), dtype=torch.long)\n",
    "    )\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "    val_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_val, dtype=torch.float32),\n",
    "        torch.tensor(np.argmax(y_val, axis=1), dtype=torch.long)\n",
    "    )\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    history = {'loss': [], 'val_loss': []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = loss_fn(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        history['loss'].append(epoch_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_X, val_y in val_dataloader:\n",
    "                val_X, val_y = val_X.to(device), val_y.to(device)\n",
    "                val_outputs = model(val_X)\n",
    "                v_loss = loss_fn(val_outputs, val_y)\n",
    "                val_loss += v_loss.item() * val_X.size(0)\n",
    "\n",
    "        val_loss /= len(val_dataloader.dataset)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        model.train()\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def partition_race_files(path_to_files, partition_size):\n",
    "    files = os.listdir(path_to_files)\n",
    "    shuffle(files)\n",
    "    n_partitions = len(files) // partition_size\n",
    "    partitions = {f'partition_{i}': [] for i in range(n_partitions)}\n",
    "    for i, file in enumerate(files):\n",
    "        partition = i % n_partitions\n",
    "        full_path = os.path.join(path_to_files, file)\n",
    "        partitions[f'partition_{partition}'].append(full_path)\n",
    "    return partitions\n",
    "\n",
    "\n",
    "# Setup and run training loop:\n",
    "\n",
    "\n",
    "train_data_location = './data/race_files'\n",
    "batch_size = 32 # (races per batch)\n",
    "\n",
    "batches = partition_race_files(train_data_location, batch_size)\n",
    "\n",
    "limit_contestants = 6\n",
    "target = 'finishOrder'\n",
    "added_features = ['leader', 'distance_to_leader']\n",
    "training_features = ['distance_to_finish', 'v_odds']\n",
    "window_timesteps = 120\n",
    "\n",
    "model = SimpleLSTM(\n",
    "    training_features=training_features,\n",
    "    added_features=added_features,\n",
    "    num_contestants=limit_contestants,\n",
    ")\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for batch, files in batches.items():\n",
    "    print(f'Loading {batch}')\n",
    "    validation_part = int(len(files) * 0.2)\n",
    "    train_files = files[validation_part:]\n",
    "    val_files = files[:validation_part]\n",
    "    X_train, y_train, X_val, y_val = get_batch(\n",
    "        train_files=train_files,\n",
    "        training_features=training_features,\n",
    "        target=target,\n",
    "        contestants=limit_contestants,\n",
    "        window_timesteps=window_timesteps,\n",
    "        randomize_training_data=False,\n",
    "        val_files=val_files\n",
    "    )\n",
    "\n",
    "    history = fit_model(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val,\n",
    "        y_val=y_val,\n",
    "        batch_size=64,\n",
    "        device=device\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1c9bef",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd079045",
   "metadata": {},
   "source": [
    "# Test update by chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0dcfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    "    log_loss,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "def get_testing_data(window_timesteps, training_features, target, limit_contestants, n_test_files=25):\n",
    "    test_data_path = './data/race_files_test'\n",
    "    pkl_files = [os.path.join(test_data_path, file) for file in os.listdir(test_data_path)]\n",
    "    pkl_files = pkl_files[:n_test_files]  # Limit for sandboxing\n",
    "    X_test, y_test = combine_races_to_tensor(\n",
    "        pkl_files=pkl_files,\n",
    "        training_features=training_features,\n",
    "        target=target,\n",
    "        limit_contestants=limit_contestants,\n",
    "        window_timesteps=window_timesteps,\n",
    "        randomize=False\n",
    "    )\n",
    "    return X_test, y_test\n",
    "\n",
    "def run_model(model, X_test, y_test, device, batch_size=32):\n",
    "    model.eval()\n",
    "\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(np.argmax(y_test, axis=1), dtype=torch.long).to(device)  # Convert test labels to class indices\n",
    "\n",
    "    test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_preds = []\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            outputs = model(batch_X)\n",
    "            loss = loss_fn(outputs, batch_y)\n",
    "            total_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "            preds = torch.softmax(outputs, dim=1)  # Get predicted probabilities\n",
    "            y_preds.append(preds.cpu().numpy())\n",
    "\n",
    "            predicted_classes = torch.argmax(preds, dim=1)\n",
    "            correct += (predicted_classes == batch_y).sum().item()\n",
    "            total += batch_X.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    y_pred_all = np.concatenate(y_preds, axis=0)\n",
    "\n",
    "    return accuracy, avg_loss, y_pred_all\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred, mode='micro'):\n",
    "    results = {}\n",
    "\n",
    "    if mode == 'micro':\n",
    "        # Flatten for metrics that treat each horse separately\n",
    "        y_true_flat = np.ndarray.flatten(np.array(y_true))\n",
    "        y_pred_flat = np.ndarray.flatten(y_pred)\n",
    "\n",
    "        results['average_precision'] = average_precision_score(y_true_flat, y_pred_flat, average='micro')\n",
    "        results['brier_score'] = brier_score_loss(y_true_flat, y_pred_flat)\n",
    "        results['log_loss'] = log_loss(y_true_flat, y_pred_flat)\n",
    "\n",
    "        # Curves\n",
    "        prob_true, prob_pred = calibration_curve(y_true_flat, y_pred_flat, n_bins=10)\n",
    "        fpr, tpr, _ = roc_curve(y_true_flat, y_pred_flat)\n",
    "        precision, recall, _ = precision_recall_curve(y_true_flat, y_pred_flat)\n",
    "\n",
    "        results['calibration_curve'] = {'prob_true': prob_true.tolist(), 'prob_pred': prob_pred.tolist()}\n",
    "        results['roc_curve'] = {'fpr': fpr.tolist(), 'tpr': tpr.tolist(), 'auc': auc(fpr, tpr)}\n",
    "        results['pr_curve'] = {'precision': precision.tolist(), 'recall': recall.tolist()}\n",
    "\n",
    "    elif mode == 'macro':\n",
    "        # Winner prediction by argmax\n",
    "        y_pred_indices = np.argmax(y_pred, axis=1)\n",
    "        y_true_indices = np.argmax(y_true, axis=1)  # Assuming y_true is still multi-hot\n",
    "\n",
    "        winner_accuracy = np.mean(y_pred_indices == y_true_indices)\n",
    "        results['winner_accuracy'] = winner_accuracy\n",
    "\n",
    "    return results\n",
    "\n",
    "# Main testing block\n",
    "X_test, y_test = get_testing_data(\n",
    "    window_timesteps=window_timesteps,\n",
    "    training_features=training_features,\n",
    "    target=target,\n",
    "    limit_contestants=limit_contestants\n",
    ")\n",
    "\n",
    "accuracy, loss, y_pred = run_model(model, X_test, y_test, device)\n",
    "\n",
    "# Compute both micro (probabilities) and macro (winner picking) evaluations\n",
    "micro_metrics = evaluate_predictions(y_test, y_pred, mode='micro')\n",
    "macro_metrics = evaluate_predictions(y_test, y_pred, mode='macro')\n",
    "\n",
    "print(\"\\n--- Scalar Metrics ---\")\n",
    "print(json.dumps({\n",
    "    'model_accuracy': accuracy,\n",
    "    'model_loss': loss,\n",
    "    **micro_metrics  # unpack micro metrics here\n",
    "}, indent=4))\n",
    "\n",
    "print(\"\\n--- Winner Prediction Metrics ---\")\n",
    "print(json.dumps(macro_metrics, indent=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-inplay_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
